%% This is file `elsarticle-template-1-num.tex',
%%
%% Copyright 2009 Elsevier Ltd
%%
%% This file is part of the 'Elsarticle Bundle'.
%% ---------------------------------------------
%%
%% It may be distributed under the conditions of the LaTeX Project Public
%% License, either version 1.2 of this license or (at your option) any
%% later version.  The latest version of this license is in
%%    http://www.latex-project.org/lppl.txt
%% and version 1.2 or later is part of all distributions of LaTeX
%% version 1999/12/01 or later.
%%
%% The list of all files belonging to the 'Elsarticle Bundle' is
%% given in the file `manifest.txt'.
%%
%% Template article for Elsevier's document class `elsarticle'
%% with numbered style bibliographic references
%%
%% $Id: elsarticle-template-1-num.tex 149 2009-10-08 05:01:15Z rishi $
%% $URL: http://lenova.river-valley.com/svn/elsbst/trunk/elsarticle-template-1-num.tex $
%%

%\documentclass[preprint,authoryear,review,12pt]{elsarticle}
\documentclass[final,5p,times,twocolumn]{elsarticle}

%% Use the option review to obtain double line spacing
%% \documentclass[preprint,review,12pt]{elsarticle}

%% Use the options 1p,two column; 3p; 3p,twocolumn; 5p; or 5p,twocolumn
%% for a journal layout:
%% \documentclass[final,1p,times]{elsarticle}
%% \documentclass[final,1p,times,twocolumn]{elsarticle}
%% \documentclass[final,3p,times]{elsarticle}
%% \documentclass[final,3p,times,twocolumn]{elsarticle}
%% \documentclass[final,5p,times]{elsarticle}
%% \documentclass[final,5p,times,twocolumn]{elsarticle}


\usepackage{color}
\usepackage{multirow,booktabs,ctable,array}
\usepackage{lscape}
\usepackage{amsmath}
\usepackage{lineno}
\usepackage{ulem}
\usepackage{setspace}
\usepackage{listings}
\usepackage{float}
\usepackage{listings}
\usepackage{color,colortbl}
\usepackage{rccol}
\usepackage[table]{xcolor}

    \definecolor{listcomment}{rgb}{0.0,0.5,0.0}
    \definecolor{listkeyword}{rgb}{0.0,0.0,0.5}
    \definecolor{listnumbers}{gray}{0.65}
    \definecolor{listlightgray}{gray}{0.955}
    \definecolor{listwhite}{gray}{1.0}
    \definecolor{lightcyan}{rgb}{0.88,1,1}

\newcommand{\lstsetcpplong}
{
\lstset{frame = tb,
        framerule = 0.25pt,
        float,
        fontadjust,
        backgroundcolor={\color{listlightgray}},
        basicstyle = {\ttfamily\scriptsize},
        keywordstyle = {\ttfamily\color{listkeyword}\textbf},
        identifierstyle = {\ttfamily},
        commentstyle = {\ttfamily\color{listcomment}\textit},
        stringstyle = {\ttfamily},
        showstringspaces = false,
        showtabs = false,
        numbers = none,
        numbersep = 6pt,
        numberstyle={\ttfamily\color{listnumbers}},
        tabsize = 2,
        language=,
        floatplacement=!h,
        caption={\small \baselineskip 12pt DiReCT long command line menu which is invoked using the `{\ttfamily {-}{-}help}' option.  The short command line menu is obtained by typing `{\ttfamily {-}h}'},
        captionpos=b,
        label=listing:long
        }
}

\floatstyle{plain}
\newfloat{command}{thp}{lop}
\floatname{command}{Command}

%\usepackage[nomarkers,notablist]{endfloat}

%% if you use PostScript figures in your article
%% use the graphics package for simple commands
%% \usepackage{graphics}
%% or use the graphicx package for more complicated commands
%% \usepackage{graphicx}
%% or use the epsfig package if you prefer to use the old commands
%% \usepackage{epsfig}

%% The amssymb package provides various useful mathematical symbols
\usepackage{amssymb}
%% The amsthm package provides extended theorem environments
% \usepackage{amsthm}
 
 \usepackage{makecell}

%% The lineno packages adds line numbers. Start line numbering with
%% \begin{linenumbers}, end it with \end{linenumbers}. Or switch it on
%% for the whole article with \linenumbers after \end{frontmatter}.
%% \usepackage{lineno}

%% natbib.sty is loaded by default. However, natbib options can be
%% provided with \biboptions{...} command. Following options are
%% valid:

%%   round  -  round parentheses are used (default)
%%   square -  square brackets are used   [option]
%%   curly  -  curly braces are used      {option}
%%   angle  -  angle brackets are used    <option>
%%   semicolon  -  multiple citations separated by semi-colon
%%   colon  - same as semicolon, an earlier confusion
%%   comma  -  separated by comma
%%   numbers-  selects numerical citations
%%   super  -  numerical citations as superscripts
%%   sort   -  sorts multiple citations according to order in ref. list
%%   sort&compress   -  like sort, but also compresses numerical citations
%%   compress - compresses without sorting
%%
%% \biboptions{comma,round}

% \biboptions{}

\providecommand{\OO}[1]{\operatorname{O}\bigl(#1\bigr)}

\graphicspath{
             {./Figures/}
             }

\long\def\symbolfootnote[#1]#2{\begingroup%
\def\thefootnote{\fnsymbol{footnote}}\footnote[#1]{#2}\endgroup}



\journal{NeuroImage}

\begin{document}


\begin{frontmatter}

\title{Tilting at Algorithmic Windmills}

\author[label1]{Nicholas J.~Tustison
  \fnref{label0}}
  \fntext[label0]{\scriptsize Corresponding author:  PO Box 801339, Charlottesville, VA 22908; T:  434-924-7730; email address:  ntustison@virginia.edu.
  }
\author[label2]{Brian B.~Avants (combined first author, second author or senior author?)}
\address[label1]{Department of Radiology and Medical Imaging, University of Virginia, Charlottesville, VA}
\address[label2]{Penn Image Computing and Science Laboratory, University of Pennsylvania,
                Philadelphia, PA}

%\maketitle

\linenumbers

\begin{abstract} 
Exploration of neuroscience hypotheses have been  enhanced
by the increased availability of high-performance computational resources, large-scale
communal efforts such as the Insight Toolkit and the R statistical project and
algorithmic advancements for data transformations and processing. 
An integral component of the vetting process for novel algorithmic techniques
includes comparison with other methods previously
established within the community.  Public availability, including 
open source distribution, of established packages has significantly 
facilitated these comparative evaluations.  However, complementing the
recent set of papers pointing to serious methodological and statistical
bias considerations in neuroimaging research, we point out potential 
issues associated with a type of measurement bias in comparative algorithmic
evaluations and propose a set of guidelines for authors and reviewers
to minimize this confound.
\end{abstract}
\begin{keyword}
open science \sep reproducibility 
%% keywords here, in the form: keyword \sep keyword
\end{keyword}

\end{frontmatter}
%
%
\newpage

%% MSC codes here, in the form: \MSC code \sep code
%% or \MSC[2008] code \sep code (2000 is the default)

%%
%% Start line numbering here if you want
%%
% \linenumbers

%% The Appendices part is started with the command \appendix;
%% appendix sections are then done as normal sections
%% \appendix

%% \section{}
%% \label{}

%% References
%%
%% Following citation commands can be used in the body text:
%% Usage of \cite is as follows:
%%   \citep{key}          ==>>  [#]
%%   \cite[chap. 2]{key} ==>>  [#, chap. 2]
%%   \citet{key}         ==>>  Author [#]

%% main text

\section{Introduction}
The neuroimaging community has benefited from the proliferation
of imaging software.  Established packages such as SPM from the 
Wellcome Trust Centre for Neuroimaging \cite{Ashburner2012},
the FMRIB Software Library (FSL) \cite{Jenkinson2012}, and
the AFNI toolkit \cite{cox2012} have aided neuroimaging researchers 
around the world in performing complex analyses as part of 
ongoing neuroscience research.  Parallel to this line of
inquiry is continued algorithmic innovation for improvement
in analysis tools.  

As fellow scientists who actively participate in this type of 
research, we have noticed several publications in which a principle
component involves the comparison of algorithms.  One of our
concerns is the lack of detail with which these comparisons are
presented and the corresponding possibility of {\it instrumentation
bias} \cite{sackett1979} (considering software  as a type of 
instrument requiring proper ``calibration'' for accurate measurements).  
In this editorial we propose an initial set of guidelines for minimal
reporting of algorithmic usage to minimize such bias understanding that 
the discussion will hopefully 
elicit a much more comprehensive response from the larger community.

Although previous articles have discussed similar concerns, oftentimes
within a much larger context (e.g. fMRI reporting \cite{poldrack2008}), 
we are particularly interested in comparative evaluations of software
and provide additional discussion through experience and actual 
examples found within the literature.
It is hoped that this commentary serves to raise awareness to both 
authors and reviewers to such problematic issues (not unlike other
recent articles detailing additional potential sources of methodological 
bias \cite{kriegeskorte2009,vul2012,tustison2012}).




\section{Guidelines}

\subsection{Parameters should be included (perhaps the precise command line call)}
Perhaps the most blatantly egregious sin is omitting 

\subsection{Hassle the developers for a set of default parameters}

\subsection{Scripts used to invoke the algorithms should be posted}

\subsection{Comparisons should be performed on publicly available data}

\subsection{Corollary to the above:  Resulting images should be publicly posted}

\subsection{Scripts used to create the plots should also be posted}

\subsection{When possible, consultation should be made with the original authors}

\subsection{Provide details of where the algorithm was obtained}

\subsection{Provide system details of where the algorithm was run}

\subsection{Avoid confirmation bias:  Don't code up your own version particularly if one
is already available}

\subsection{Co-authors should verify findings}

\subsection{Properly contextualize comparisons}
Accuracy is important but other considerations should be included such
as biological plausibility.  Torsten's CURT algorithm could produce an ``accurate''
registration but not one which is biologically plausible.


\section{Conclusion}


\section{Acknowledgments}

%% References with bibTeX database:

%\section*{Acknowledgments}



\section{Notes/Thoughts}
\begin{itemize}
  \item Several kinds of bias have cropped up in the neuroimaging
  community recently:
  \begin{itemize}
    \item{methodological bias}:  Kreikesgorte
    \item{statistical bias}:  Vul2009, Tustison2012
    \item  What about the dead salmon fmri study---multiple comparisons correction?
    \item The single subject VBM study (assuming the single subject is representative of the population).
    \item{overview}:  9 circles of scientific hell ---neuroskeptic %http://blogs.discovermagazine.com/neuroskeptic/?p=1205#.UYZxyJWO7Tx
    \item Types of measurement bias: \cite{sackett1979}
    \begin{itemize}
      \item Instrument bias (code as a type of instrument which needs to be calibrated correctly).
      \item Expectation bias (i.e. confirmation bias)
    \end{itemize}  
  \end{itemize}
  We are concerned with the latter two.
  \item How does one avoid confirmation bias?  If I'm comparing my
  algorithm to somebody else's algorithm, I'm going to be naturally
  predisposed to confirmatory evidence that my algorithm is better
  while neglecting (most likely not with intent of doing so) evidence
  that disconfirms my original belief (that my algorithm is better).
  Richard Feynman quote (Cargo Cult Science):  
  \begin{quote} 
  The first principle [of science] is that you must not fool yourself—--and you are the easiest person to fool. So you have to be very careful about that. After you've not fooled yourself, it's easy not to fool other scientists. You just have to be honest in a conventional way after that.
  \end{quote}
  \item One particular aspect of the previous item is that it needs 
  to be highlighted if somebody codes up the algorithm
  to be compared themselves.  Writing bug-free code is difficult.  Look
  at how many bug fixes are provided by the ITK community on a daily
  basis.  
  \item Also, is simply saying that one algorithm is better than 
  another sufficient?  Should there be some theoretical explanation
  for it.  For example, when I wrote my DMFFD image registration paper,
  the comparison wasn't IRTK vs. DMFFD but rather FFD vs. DMFFD and
  there were theoretical reasons why performance should be better
  with the latter.  Also, I insisted to the reviewer on not using IRTK 
  for comparison since there are also so many other performance-related
  issues (type of interpolation, gradient step, metric, metric implementation, etc.) which would confound
  comparisons.  Also, it probably helped that the theme had a more specific,
  more verifiable focus, i.e. DMFFD produces a more efficient energy minimizer
  since it acts as a preconditioner in the standard gradient descent
  optimization.
  \item Comparisons are best made with publicly available data and
  results of the comparisons should be made available.
  \item Operating system needs to be defined.  Freesurfer results
  varied with MacOSx.
  \item Ideally, the authors of the new algorithm would work
  with the authors of the compared algorithm.  Given human
  nature, this type of cooperation is not guaranteed.  However,
  a minimum set of information is needed.
  \item Arno Klein as an example of somebody who did it right.  Takes a
  lot of work.
  \item 
  \item The source of the package software needs to be defined.  For 
  example, N4 has been
  instantiated in Slicer, ANTs, and c3d (also might be implemented
  in one of Styner's NITRC projects).  However, each might use
  different default parameters and have other tweaks which effects
  performance.  In Vladimir Fonov's github repository containing 
  various processing scripts for MINC, one can see from the history
  how N4 was used but then the users switched back to N3MNI (due to 
  performance issues?).  However, they used N4 out of the c3d package
  which the original authors (N.T./B.A.) haven't touched in three years
  so the parameters aren't optimal (shrink factors = 4, spline distance
  = 100 with 3 levels: $100\times50\times50$).  Changing these parameters 
  (which are crucial to performance) isn't
  accessible to the user from c3d.  

 \item Collaborators should help verify findings by repeating a
(representative subset of a) study independently, from scratch,
preferably on another computer perhaps even with a different operating
system.  A scientist can do this him/herself as well.  Personal
experience suggests that this procedure will often uncover coding
errors sometimes simply by forcing one to reread code or scripts again
or clarify documentation.
 
  \item
    \textcolor{blue}%{\href{http://en.wikipedia.org/wiki/Accuracy_and_precision}{Accuracy and precision (link)}} 
        wiki link--- most studies ignore precision.  it
    is critical in longitudinal studies.   precision is impacted by
    parameter choices as well as computational architecture
    (Freesurfer paper)

   \item parameters impact accuracy - e.g. clarkson's paper vs our
     recent tuning of DiReCT parameters w.r.t. expected thickness values.

  \item  Biological plausibility is important---a more accurate method
    may produce less biologically plausible results.
    Cross-referencing with other fields is critical e.g. patterns of
    MRI atrophy should match pathology distribution.  There is an art
    to this, of course.

  \item Prediction---an algorithm that yields a ``more significant''
    result is not always better.  might mean ``finds more effected
    areas'' or smaller p-values.  Testing prediction complements
    studies of significance and cumulative distribution functions.

  \item Verification is supported by open science technology for
    sharing data and code.

   \item Great resources for data-sharing:
  	\begin{itemize}
	   \item figshare
           \item MIDAS 
           \item slicedrop
           \item R 
        \end{itemize}

  \item Great resources for code-sharing
  	\begin{itemize}
		  \item github
		  \item NITRC
		  \item ITK
		\end{itemize}
\end{itemize}

\section*{References}

\bibliographystyle{elsarticle-harv}
\bibliography{references}


%% Authors are advised to submit their bibtex database files. They are
%% requested to list a bibtex style file in the manuscript if they do
%% not want to use model1-num-names.bst.

%% References without bibTeX database:

% \begin{thebibliography}{00}

%% \bibitem must have the following form:
%%   \bibitem{key}...
%%

% \bibitem{}

% \end{thebibliography}


\end{document}

%%
%% End of file `elsarticle-template-1-num.tex'.
