%% This BibTeX bibliography file was created using BibDesk.
%% http://bibdesk.sourceforge.net/


%% Created for Nicholas Tustison at 2011-07-01 12:48:22 -0400 


%% Saved with string encoding Unicode (UTF-8) 



@article{le-goualher1999,
	Abstract = {Systematic mapping of the variability in cortical sulcal anatomy is an area of increasing interest which presents numerous methodological challenges. To address these issues, we have implemented sulcal extraction and assisted labeling (SEAL) to automatically extract the two-dimensional (2-D) surface ribbons that represent the median axis of cerebral sulci and to neuroanatomically label these entities. To encode the extracted three-dimensional (3-D) cortical sulcal schematic topography (CSST) we define a relational graph structure composed of two main features: vertices (representing sulci) and arcs (representing the relationships between sulci). Vertices contain a parametric representation of the surface ribbon buried within the sulcus. Points on this surface are expressed in stereotaxic coordinates (i.e., with respect to a standardized brain coordinate system). For each of these vertices, we store length, depth, and orientation as well as anatomical attributes (e.g., hemisphere, lobe, sulcus type, etc.). Each arc stores the 3-D location of the junction between sulci as well as a list of its connecting sulci. Sulcal labeling is performed semiautomatically by selecting a sulcal entity in the CSST and selecting from a menu of candidate sulcus names. In order to help the user in the labeling task, the menu is restricted to the most likely candidates by using priors for the expected sulcal spatial distribution. These priors, i.e., sulcal probabilistic maps, were created from the spatial distribution of 34 sulci traced manually on 36 different subjects. Given these spatial probability maps, the user is provided with the likelihood that the selected entity belongs to a particular sulcus. The cortical structure representation obtained by SEAL is suitable to extract statistical information about both the spatial and the structural composition of the cerebral cortical topography. This methodology allows for the iterative construction of a successively more complete statistical models of the cerebral topography containing spatial distributions of the most important structures, their morphometrics, and their structural components.},
	Author = {Le Goualher, G and Procyk, E and Collins, D L and Venugopal, R and Barillot, C and Evans, A C},
	Date-Added = {2011-06-30 20:15:46 -0400},
	Date-Modified = {2011-06-30 20:15:46 -0400},
	Doi = {10.1109/42.764891},
	Journal = {IEEE Trans Med Imaging},
	Journal-Full = {IEEE transactions on medical imaging},
	Mesh = {Algorithms; Cerebral Cortex; Humans; Image Processing, Computer-Assisted; Likelihood Functions; Magnetic Resonance Imaging; Reproducibility of Results},
	Month = {Mar},
	Number = {3},
	Pages = {206-17},
	Pmid = {10363699},
	Pst = {ppublish},
	Title = {Automated extraction and variability analysis of sulcal neuroanatomy},
	Volume = {18},
	Year = {1999},
	Bdsk-Url-1 = {http://dx.doi.org/10.1109/42.764891}}

@article{scott2009,
	Abstract = {Several algorithms for measuring the cortical thickness in the human brain from MR image volumes have been described in the literature, the majority of which rely on fitting deformable models to the inner and outer cortical surfaces. However, the constraints applied during the model fitting process in order to enforce spherical topology and to fit the outer cortical surface in narrow sulci, where the cerebrospinal fluid (CSF) channel may be obscured by partial voluming, may introduce bias in some circumstances, and greatly increase the processor time required. In this paper we describe an alternative, voxel based technique that measures the cortical thickness using inversion recovery anatomical MR images. Grey matter, white matter and CSF are identified through segmentation, and edge detection is used to identify the boundaries between these tissues. The cortical thickness is then measured along the local 3D surface normal at every voxel on the inner cortical surface. The method was applied to 119 normal volunteers, and validated through extensive comparisons with published measurements of both cortical thickness and rate of thickness change with age. We conclude that the proposed technique is generally faster than deformable model-based alternatives, and free from the possibility of model bias, but suffers no reduction in accuracy. In particular, it will be applicable in data sets showing severe cortical atrophy, where thinning of the gyri leads to points of high curvature, and so the fitting of deformable models is problematic.},
	Author = {Scott, M L J and Bromiley, P A and Thacker, N A and Hutchinson, C E and Jackson, A},
	Date-Added = {2011-06-30 20:14:19 -0400},
	Date-Modified = {2011-06-30 20:14:19 -0400},
	Doi = {10.1016/j.media.2008.10.006},
	Journal = {Med Image Anal},
	Journal-Full = {Medical image analysis},
	Mesh = {Algorithms; Artificial Intelligence; Cerebral Cortex; Computer Simulation; Humans; Image Enhancement; Image Interpretation, Computer-Assisted; Imaging, Three-Dimensional; Magnetic Resonance Imaging; Models, Neurological; Pattern Recognition, Automated; Phantoms, Imaging; Reproducibility of Results; Sensitivity and Specificity},
	Month = {Apr},
	Number = {2},
	Pages = {269-85},
	Pmid = {19068276},
	Pst = {ppublish},
	Title = {A fast, model-independent method for cerebral cortical thickness estimation using MRI},
	Volume = {13},
	Year = {2009},
	Bdsk-Url-1 = {http://dx.doi.org/10.1016/j.media.2008.10.006}}

@article{macdonald2000,
	Abstract = {Automatic computer processing of large multidimensional images such as those produced by magnetic resonance imaging (MRI) is greatly aided by deformable models, which are used to extract, identify, and quantify specific neuroanatomic structures. A general method of deforming polyhedra is presented here, with two novel features. First, explicit prevention of self-intersecting surface geometries is provided, unlike conventional deformable models, which use regularization constraints to discourage but not necessarily prevent such behavior. Second, deformation of multiple surfaces with intersurface proximity constraints allows each surface to help guide other surfaces into place using model-based constraints such as expected thickness of an anatomic surface. These two features are used advantageously to identify automatically the total surface of the outer and inner boundaries of cerebral cortical gray matter from normal human MR images, accurately locating the depths of the sulci, even where noise and partial volume artifacts in the image obscure the visibility of sulci. The extracted surfaces are enforced to be simple two-dimensional manifolds (having the topology of a sphere), even though the data may have topological holes. This automatic 3-D cortex segmentation technique has been applied to 150 normal subjects, simultaneously extracting both the gray/white and gray/cerebrospinal fluid interface from each individual. The collection of surfaces has been used to create a spatial map of the mean and standard deviation for the location and the thickness of cortical gray matter. Three alternative criteria for defining cortical thickness at each cortical location were developed and compared. These results are shown to corroborate published postmortem and in vivo measurements of cortical thickness.},
	Author = {MacDonald, D and Kabani, N and Avis, D and Evans, A C},
	Date-Added = {2011-06-30 20:13:33 -0400},
	Date-Modified = {2011-06-30 20:13:33 -0400},
	Doi = {10.1006/nimg.1999.0534},
	Journal = {Neuroimage},
	Journal-Full = {NeuroImage},
	Mesh = {Algorithms; Brain Mapping; Cerebral Cortex; Humans; Image Processing, Computer-Assisted; Magnetic Resonance Imaging; Models, Neurological; Reproducibility of Results; Terminology as Topic},
	Month = {Sep},
	Number = {3},
	Pages = {340-56},
	Pmid = {10944416},
	Pst = {ppublish},
	Title = {Automated 3-D extraction of inner and outer surfaces of cerebral cortex from MRI},
	Volume = {12},
	Year = {2000},
	Bdsk-Url-1 = {http://dx.doi.org/10.1006/nimg.1999.0534}}

@article{aganj2009,
	Abstract = {Estimating the thickness of the cerebral cortex is a key step in many brain imaging studies, revealing valuable information on development or disease progression. In this work, we present a framework for measuring the cortical thickness, based on minimizing line integrals over the probability map of the gray matter in the MRI volume. We first prepare a probability map that contains the probability of each voxel belonging to the gray matter. Then, the thickness is basically defined for each voxel as the minimum line integral of the probability map on line segments centered at the point of interest. In contrast to our approach, previous methods often perform a binary-valued hard segmentation of the gray matter before measuring the cortical thickness. Because of image noise and partial volume effects, such a hard classification ignores the underlying tissue class probabilities assigned to each voxel, discarding potentially useful information. We describe our proposed method and demonstrate its performance on both artificial volumes and real 3D brain MRI data from subjects with Alzheimer's disease and healthy individuals.},
	Author = {Aganj, Iman and Sapiro, Guillermo and Parikshak, Neelroop and Madsen, Sarah K and Thompson, Paul M},
	Date-Added = {2011-06-30 20:02:28 -0400},
	Date-Modified = {2011-06-30 20:02:28 -0400},
	Doi = {10.1002/hbm.20740},
	Journal = {Hum Brain Mapp},
	Journal-Full = {Human brain mapping},
	Mesh = {Algorithms; Alzheimer Disease; Brain Mapping; Case-Control Studies; Cerebral Cortex; Follow-Up Studies; Humans; Image Processing, Computer-Assisted; Magnetic Resonance Imaging; Probability; Statistics as Topic},
	Month = {Oct},
	Number = {10},
	Pages = {3188-99},
	Pmc = {PMC2903209},
	Pmid = {19219850},
	Pst = {ppublish},
	Title = {Measurement of cortical thickness from MRI by minimum line integrals on soft-classified tissue},
	Volume = {30},
	Year = {2009},
	Bdsk-Url-1 = {http://dx.doi.org/10.1002/hbm.20740}}

@article{chung2005,
	Abstract = {We present a novel data smoothing and analysis framework for cortical thickness data defined on the brain cortical manifold. Gaussian kernel smoothing, which weights neighboring observations according to their 3D Euclidean distance, has been widely used in 3D brain images to increase the signal-to-noise ratio. When the observations lie on a convoluted brain surface, however, it is more natural to assign the weights based on the geodesic distance along the surface. We therefore develop a framework for geodesic distance-based kernel smoothing and statistical analysis on the cortical manifolds. As an illustration, we apply our methods in detecting the regions of abnormal cortical thickness in 16 high functioning autistic children via random field based multiple comparison correction that utilizes the new smoothing technique.},
	Author = {Chung, Moo K and Robbins, Steven M and Dalton, Kim M and Davidson, Richard J and Alexander, Andrew L and Evans, Alan C},
	Date-Added = {2011-06-30 19:48:43 -0400},
	Date-Modified = {2011-06-30 19:48:43 -0400},
	Doi = {10.1016/j.neuroimage.2004.12.052},
	Journal = {Neuroimage},
	Journal-Full = {NeuroImage},
	Mesh = {Adolescent; Adult; Algorithms; Autistic Disorder; Cerebral Cortex; Data Interpretation, Statistical; Humans; Image Processing, Computer-Assisted; Magnetic Resonance Imaging; Male},
	Month = {May},
	Number = {4},
	Pages = {1256-65},
	Pmid = {15850743},
	Pst = {ppublish},
	Title = {Cortical thickness analysis in autism with heat kernel smoothing},
	Volume = {25},
	Year = {2005},
	Bdsk-Url-1 = {http://dx.doi.org/10.1016/j.neuroimage.2004.12.052}}

@article{fischl2000,
	Abstract = {Accurate and automated methods for measuring the thickness of human cerebral cortex could provide powerful tools for diagnosing and studying a variety of neurodegenerative and psychiatric disorders. Manual methods for estimating cortical thickness from neuroimaging data are labor intensive, requiring several days of effort by a trained anatomist. Furthermore, the highly folded nature of the cortex is problematic for manual techniques, frequently resulting in measurement errors in regions in which the cortical surface is not perpendicular to any of the cardinal axes. As a consequence, it has been impractical to obtain accurate thickness estimates for the entire cortex in individual subjects, or group statistics for patient or control populations. Here, we present an automated method for accurately measuring the thickness of the cerebral cortex across the entire brain and for generating cross-subject statistics in a coordinate system based on cortical anatomy. The intersubject standard deviation of the thickness measures is shown to be less than 0.5 mm, implying the ability to detect focal atrophy in small populations or even individual subjects. The reliability and accuracy of this new method are assessed by within-subject test-retest studies, as well as by comparison of cross-subject regional thickness measures with published values.},
	Author = {Fischl, B and Dale, A M},
	Date-Added = {2011-06-30 19:47:02 -0400},
	Date-Modified = {2011-06-30 19:47:02 -0400},
	Doi = {10.1073/pnas.200033797},
	Journal = {Proc Natl Acad Sci U S A},
	Journal-Full = {Proceedings of the National Academy of Sciences of the United States of America},
	Mesh = {Cerebral Cortex; Humans; Image Processing, Computer-Assisted; Magnetic Resonance Imaging},
	Month = {Sep},
	Number = {20},
	Pages = {11050-5},
	Pmc = {PMC27146},
	Pmid = {10984517},
	Pst = {ppublish},
	Title = {Measuring the thickness of the human cerebral cortex from magnetic resonance images},
	Volume = {97},
	Year = {2000},
	Bdsk-Url-1 = {http://dx.doi.org/10.1073/pnas.200033797}}

@article{das2009,
	Abstract = {Cortical thickness is an important biomarker for image-based studies of the brain. A diffeomorphic registration based cortical thickness (DiReCT) measure is introduced where a continuous one-to-one correspondence between the gray matter-white matter interface and the estimated gray matter-cerebrospinal fluid interface is given by a diffeomorphic mapping in the image space. Thickness is then defined in terms of a distance measure between the interfaces of this sheet like structure. This technique also provides a natural way to compute continuous estimates of thickness within buried sulci by preventing opposing gray matter banks from intersecting. In addition, the proposed method incorporates neuroanatomical constraints on thickness values as part of the mapping process. Evaluation of this method is presented on synthetic images. As an application to brain images, a longitudinal study of thickness change in frontotemporal dementia (FTD) spectrum disorder is reported.},
	Author = {Das, Sandhitsu R and Avants, Brian B and Grossman, Murray and Gee, James C},
	Date-Added = {2011-06-30 19:44:51 -0400},
	Date-Modified = {2011-06-30 19:44:51 -0400},
	Doi = {10.1016/j.neuroimage.2008.12.016},
	Journal = {Neuroimage},
	Journal-Full = {NeuroImage},
	Mesh = {Aged; Algorithms; Brain Mapping; Cerebral Cortex; Dementia; Humans; Image Interpretation, Computer-Assisted; Magnetic Resonance Imaging; Middle Aged},
	Month = {Apr},
	Number = {3},
	Pages = {867-79},
	Pmc = {PMC2836782},
	Pmid = {19150502},
	Pst = {ppublish},
	Title = {Registration based cortical thickness measurement},
	Volume = {45},
	Year = {2009},
	Bdsk-Url-1 = {http://dx.doi.org/10.1016/j.neuroimage.2008.12.016}}

@article{lohmann2003,
	Abstract = {We describe a new approach to estimating the cortical thickness of human brains using magnetic resonance imaging data. Our algorithm is part of a processing chain consisting of a brain segmentation (skull stripping), as well as white and grey matter segmentation procedures. In this paper, only the grey matter segmentation together with the cortical thickness estimation is described. In contrast to many existing methods, our estimation method is voxel-based and does not use any surface meshes. While this fact poses a principal limit on the accuracy that can be achieved by our method, it offers tremendous advantages with respect to practical applicability. In particular, it is applicable to data sets showing severe cortical atrophies that involve areas of high curvature and extremely thin gyral stalks. In contrast to many other methods, it is entirely automatic and very fast with computation times of a few minutes. Our method has been used in two clinical studies involving a total of 27 patients and 23 healthy subjects.},
	Author = {Lohmann, Gabriele and Preul, Christoph and Hund-Georgiadis, Margret},
	Date-Added = {2011-06-30 19:23:23 -0400},
	Date-Modified = {2011-06-30 19:29:25 -0400},
	Journal = {Inf Process Med Imaging},
	Journal-Full = {Information processing in medical imaging : proceedings of the ... conference},
	Mesh = {Algorithms; Cerebral Cortex; Cerebrovascular Disorders; Computer Simulation; Dementia; Humans; Image Enhancement; Image Interpretation, Computer-Assisted; Imaging, Three-Dimensional; Microcirculation; Models, Biological; Pattern Recognition, Automated; Reproducibility of Results; Sensitivity and Specificity; Signal Processing, Computer-Assisted},
	Month = {Jul},
	Pages = {89-100},
	Pmid = {15344449},
	Pst = {ppublish},
	Title = {Morphology-based cortical thickness estimation},
	Volume = {18},
	Year = {2003}}

@article{jones2000,
	Abstract = {We present a novel, computerized method of examining cerebral cortical thickness. The normal cortex varies in thickness from 2 to 4 mm, reflecting the morphology of neuronal sublayers. Cortical pathologies often manifest abnormal variations in thickness, with examples of Alzheimer's disease and cortical dysplasia as thin and thick cortex, respectively. Radiologically, images are 2-D slices through a highly convoluted 3-D object. Depending on the relative orientation of the slices with respect to the object, it is impossible to deduce abnormal cortical thickness without additional information from neighboring slices. We approach the problem by applying Laplace's Equation (V2psi = 0) from mathematical physics. The volume of the cortex is represented as the domain for the solution of the differential equation, with separate boundary conditions at the gray-white junction and the gray-CSF junction. Normalized gradients of psi form a vector field, representing tangent vectors along field lines connecting both boundaries. We define the cortical thickness at any point in the cortex to be the pathlength along such lines. Key advantages of this method are that it is fully three-dimensional, and the thickness is uniquely defined for any point in the cortex. We present graphical results that map cortical thickness everywhere in a normal brain. Results show global variations in cortical thickness consistent with known neuroanatomy. The application of this technique to visualization of cortical thickness in brains with known pathology has broad clinical implications.},
	Author = {Jones, S E and Buchbinder, B R and Aharon, I},
	Date-Added = {2011-06-30 19:12:50 -0400},
	Date-Modified = {2011-06-30 19:29:25 -0400},
	Journal = {Hum Brain Mapp},
	Journal-Full = {Human brain mapping},
	Mesh = {Algorithms; Brain Mapping; Cerebral Cortex; Humans; Magnetic Resonance Imaging; Models, Neurological},
	Month = {Sep},
	Number = {1},
	Pages = {12-32},
	Pmid = {10997850},
	Pst = {ppublish},
	Title = {Three-dimensional mapping of cortical thickness using Laplace's equation},
	Volume = {11},
	Year = {2000}}

@article{nakamura2011,
	Abstract = {Measurement of changes in brain cortical thickness is useful for the assessment of regional gray matter atrophy in neurodegenerative conditions. A new longitudinal method, called CLADA (cortical longitudinal atrophy detection algorithm), has been developed for the measurement of changes in cortical thickness in magnetic resonance images (MRI) acquired over time. CLADA creates a subject-specific cortical model which is longitudinally deformed to match images from individual time points. The algorithm was designed to work reliably for lower resolution images, such as the MRIs with 1×1×5 mm(3) voxels previously acquired for many clinical trials in multiple sclerosis (MS). CLADA was evaluated to determine reproducibility, accuracy, and sensitivity. Scan-rescan variability was 0.45\% for images with 1mm(3) isotropic voxels and 0.77\% for images with 1×1×5 mm(3) voxels. The mean absolute accuracy error was 0.43 mm, as determined by comparison of CLADA measurements to cortical thickness measured directly in post-mortem tissue. CLADA's sensitivity for correctly detecting at least 0.1mm change was 86\% in a simulation study. A comparison to FreeSurfer showed good agreement (Pearson correlation=0.73 for global mean thickness). CLADA was also applied to MRIs acquired over 18 months in secondary progressive MS patients who were imaged at two different resolutions. Cortical thinning was detected in this group in both the lower and higher resolution images. CLADA detected a higher rate of cortical thinning in MS patients compared to healthy controls over 2 years. These results show that CLADA can be used for reliable measurement of cortical atrophy in longitudinal studies, even in lower resolution images.},
	Author = {Nakamura, Kunio and Fox, Robert and Fisher, Elizabeth},
	Date-Added = {2011-06-30 19:00:15 -0400},
	Date-Modified = {2011-06-30 19:29:25 -0400},
	Doi = {10.1016/j.neuroimage.2010.07.052},
	Journal = {Neuroimage},
	Journal-Full = {NeuroImage},
	Mesh = {Algorithms; Atrophy; Cerebral Cortex; Humans; Longitudinal Studies; Magnetic Resonance Imaging; Models, Neurological; Multiple Sclerosis; Postmortem Changes; Reproducibility of Results; Sensitivity and Specificity; Spine; Time Factors},
	Month = {Jan},
	Number = {1},
	Pages = {278-89},
	Pmc = {PMC2965022},
	Pmid = {20674750},
	Pst = {ppublish},
	Title = {CLADA: cortical longitudinal atrophy detection algorithm},
	Volume = {54},
	Year = {2011},
	Bdsk-Url-1 = {http://dx.doi.org/10.1016/j.neuroimage.2010.07.052}}

@article{rocha2007,
	Abstract = {We present a novel approach to efficiently compute thickness, correspondence, and gridding of tissues between two simply connected boundaries. The solution of Laplace's equation within the tissue region provides a harmonic function whose gradient flow determines the correspondence trajectories going from one boundary to the other. The proposed method uses and expands upon two recently introduced techniques in order to compute thickness and correspondences based on these trajectories. Pairs of partial differential equations are efficiently computed within an Eulerian framework and combined with a Lagrangian approach so that correspondences trajectories are partially constructed when necessary. Examples are presented in order to compare the performance of this method with those of the pure Lagrangian and pure Eulerian approaches. Results show that the proposed technique takes advantage of both the speed of the Eulerian approach and the accuracy of the Lagrangian approach.},
	Author = {Rocha, Kelvin R and Yezzi, Jr, Anthony J and Prince, Jerry L},
	Date-Added = {2011-06-30 18:44:43 -0400},
	Date-Modified = {2011-06-30 19:29:25 -0400},
	Journal = {IEEE Trans Image Process},
	Journal-Full = {IEEE transactions on image processing : a publication of the IEEE Signal Processing Society},
	Mesh = {Algorithms; Artificial Intelligence; Heart; Humans; Image Enhancement; Image Interpretation, Computer-Assisted; Imaging, Three-Dimensional; Magnetic Resonance Imaging; Models, Cardiovascular; Pattern Recognition, Automated; Reproducibility of Results; Sensitivity and Specificity; Subtraction Technique},
	Month = {Mar},
	Number = {3},
	Pages = {636-48},
	Pmid = {17357725},
	Pst = {ppublish},
	Title = {A hybrid Eulerian-Lagrangian approach for thickness, correspondence, and gridding of annular tissues},
	Volume = {16},
	Year = {2007}}

@article{acosta2009,
	Abstract = {Accurate cortical thickness estimation is important for the study of many neurodegenerative diseases. Many approaches have been previously proposed, which can be broadly categorised as mesh-based and voxel-based. While the mesh-based approaches can potentially achieve subvoxel resolution, they usually lack the computational efficiency needed for clinical applications and large database studies. In contrast, voxel-based approaches, are computationally efficient, but lack accuracy. The aim of this paper is to propose a novel voxel-based method based upon the Laplacian definition of thickness that is both accurate and computationally efficient. A framework was developed to estimate and integrate the partial volume information within the thickness estimation process. Firstly, in a Lagrangian step, the boundaries are initialized using the partial volume information. Subsequently, in an Eulerian step, a pair of partial differential equations are solved on the remaining voxels to finally compute the thickness. Using partial volume information significantly improved the accuracy of the thickness estimation on synthetic phantoms, and improved reproducibility on real data. Significant differences in the hippocampus and temporal lobe between healthy controls (NC), mild cognitive impaired (MCI) and Alzheimer's disease (AD) patients were found on clinical data from the ADNI database. We compared our method in terms of precision, computational speed and statistical power against the Eulerian approach. With a slight increase in computation time, accuracy and precision were greatly improved. Power analysis demonstrated the ability of our method to yield statistically significant results when comparing AD and NC. Overall, with our method the number of samples is reduced by 25\% to find significant differences between the two groups.},
	Author = {Acosta, Oscar and Bourgeat, Pierrick and Zuluaga, Maria A and Fripp, Jurgen and Salvado, Olivier and Ourselin, S{\'e}bastien and {Alzheimer's Disease Neuroimaging Initiative}},
	Date-Added = {2011-06-30 18:43:28 -0400},
	Date-Modified = {2011-06-30 19:29:25 -0400},
	Doi = {10.1016/j.media.2009.07.003},
	Journal = {Med Image Anal},
	Journal-Full = {Medical image analysis},
	Mesh = {Aged; Aged, 80 and over; Algorithms; Alzheimer Disease; Artificial Intelligence; Brain; Cognition Disorders; Female; Humans; Image Enhancement; Image Interpretation, Computer-Assisted; Imaging, Three-Dimensional; Magnetic Resonance Imaging; Male; Middle Aged; Pattern Recognition, Automated; Reproducibility of Results; Sensitivity and Specificity},
	Month = {Oct},
	Number = {5},
	Pages = {730-43},
	Pmc = {PMC3068613},
	Pmid = {19648050},
	Pst = {ppublish},
	Title = {Automated voxel-based 3D cortical thickness measurement in a combined Lagrangian-Eulerian PDE approach using partial volume maps},
	Volume = {13},
	Year = {2009},
	Bdsk-Url-1 = {http://dx.doi.org/10.1016/j.media.2009.07.003}}

@article{clarkson2011,
	Abstract = {Cortical thickness estimation performed in-vivo via magnetic resonance imaging is an important technique for the diagnosis and understanding of the progression of neurodegenerative diseases. Currently, two different computational paradigms exist, with methods generally classified as either surface or voxel-based. This paper provides a much needed comparison of the surface-based method FreeSurfer and two voxel-based methods using clinical data. We test the effects of computing regional statistics using two different atlases and demonstrate that this makes a significant difference to the cortical thickness results. We assess reproducibility, and show that FreeSurfer has a regional standard deviation of thickness difference on same day scans that is significantly lower than either a Laplacian or Registration based method and discuss the trade off between reproducibility and segmentation accuracy caused by bending energy constraints. We demonstrate that voxel-based methods can detect similar patterns of group-wise differences as well as FreeSurfer in typical applications such as producing group-wise maps of statistically significant thickness change, but that regional statistics can vary between methods. We use a Support Vector Machine to classify patients against controls and did not find statistically significantly different results with voxel based methods compared to FreeSurfer. Finally we assessed longitudinal performance and concluded that currently FreeSurfer provides the most plausible measure of change over time, with further work required for voxel based methods.},
	Author = {Clarkson, Matthew J and Cardoso, M Jorge and Ridgway, Gerard R and Modat, Marc and Leung, Kelvin K and Rohrer, Jonathan D and Fox, Nick C and Ourselin, S{\'e}bastien},
	Date-Added = {2011-06-30 18:42:55 -0400},
	Date-Modified = {2011-06-30 19:29:25 -0400},
	Doi = {10.1016/j.neuroimage.2011.05.053},
	Journal = {Neuroimage},
	Journal-Full = {NeuroImage},
	Month = {May},
	Pmid = {21640841},
	Pst = {aheadofprint},
	Title = {A comparison of voxel and surface based cortical thickness estimation methods},
	Year = {2011},
	Bdsk-Url-1 = {http://dx.doi.org/10.1016/j.neuroimage.2011.05.053}}
