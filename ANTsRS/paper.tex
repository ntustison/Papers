%% This is file `elsarticle-template-1-num.tex',
%%
%% Copyright 2009 Elsevier Ltd
%%
%% This file is part of the 'Elsarticle Bundle'.
%% ---------------------------------------------
%%
%% It may be distributed under the conditions of the LaTeX Project Public
%% License, either version 1.2 of this license or (at your option) any
%% later version.  The latest version of this license is in
%%    http://www.latex-project.org/lppl.txt
%% and version 1.2 or later is part of all distributions of LaTeX
%% version 1999/12/01 or later.
%%
%% The list of all files belonging to the 'Elsarticle Bundle' is
%% given in the file `manifest.txt'.
%%
%% Template article for Elsevier's document class `elsarticle'
%% with numbered style bibliographic references
%%
%% $Id: elsarticle-template-1-num.tex 149 2009-10-08 05:01:15Z rishi $
%% $URL: http://lenova.river-valley.com/svn/elsbst/trunk/elsarticle-template-1-num.tex $
%%

%\documentclass[preprint,authoryear,review,12pt]{elsarticle}
\documentclass[final,5p,times,twocolumn]{elsarticle}

%% Use the option review to obtain double line spacing
%% \documentclass[preprint,review,12pt]{elsarticle}

%% Use the options 1p,two column; 3p; 3p,twocolumn; 5p; or 5p,twocolumn
%% for a journal layout:
%% \documentclass[final,1p,times]{elsarticle}
%% \documentclass[final,1p,times,twocolumn]{elsarticle}
%% \documentclass[final,3p,times]{elsarticle}
%% \documentclass[final,3p,times,twocolumn]{elsarticle}
%% \documentclass[final,5p,times]{elsarticle}
%% \documentclass[final,5p,times,twocolumn]{elsarticle}


\usepackage{color}
\usepackage{multirow,booktabs,ctable,array}
\usepackage{lscape}
\usepackage{amsmath}
\usepackage{lineno}
\usepackage{ulem}
\usepackage{setspace}
\usepackage{listings}
\usepackage{float}
\usepackage{listings}
\usepackage{color,colortbl}
\usepackage{rccol}
\usepackage[table]{xcolor}

    \definecolor{listcomment}{rgb}{0.0,0.5,0.0}
    \definecolor{listkeyword}{rgb}{0.0,0.0,0.5}
    \definecolor{listnumbers}{gray}{0.65}
    \definecolor{listlightgray}{gray}{0.955}
    \definecolor{listwhite}{gray}{1.0}
    \definecolor{lightcyan}{rgb}{0.88,1,1}

\newcommand{\lstsetcpplong}
{
\lstset{frame = tb,
        framerule = 0.25pt,
        float,
        fontadjust,
        backgroundcolor={\color{listlightgray}},
        basicstyle = {\ttfamily\scriptsize},
        keywordstyle = {\ttfamily\color{listkeyword}\textbf},
        identifierstyle = {\ttfamily},
        commentstyle = {\ttfamily\color{listcomment}\textit},
        stringstyle = {\ttfamily},
        showstringspaces = false,
        showtabs = false,
        numbers = none,
        numbersep = 6pt,
        numberstyle={\ttfamily\color{listnumbers}},
        tabsize = 2,
        language=,
        floatplacement=!h,
        caption={\small \baselineskip 12pt DiReCT long command line menu which is invoked using the `{\ttfamily {-}{-}help}' option.  The short command line menu is obtained by typing `{\ttfamily {-}h}'},
        captionpos=b,
        label=listing:long
        }
}

\floatstyle{plain}
\newfloat{command}{thp}{lop}
\floatname{command}{Command}

%\usepackage[nomarkers,notablist]{endfloat}

%% if you use PostScript figures in your article
%% use the graphics package for simple commands
%% \usepackage{graphics}
%% or use the graphicx package for more complicated commands
%% \usepackage{graphicx}
%% or use the epsfig package if you prefer to use the old commands
%% \usepackage{epsfig}

%% The amssymb package provides various useful mathematical symbols
\usepackage{amssymb}
%% The amsthm package provides extended theorem environments
% \usepackage{amsthm}
 
 \usepackage{makecell}

%% The lineno packages adds line numbers. Start line numbering with
%% \begin{linenumbers}, end it with \end{linenumbers}. Or switch it on
%% for the whole article with \linenumbers after \end{frontmatter}.
%% \usepackage{lineno}

%% natbib.sty is loaded by default. However, natbib options can be
%% provided with \biboptions{...} command. Following options are
%% valid:

%%   round  -  round parentheses are used (default)
%%   square -  square brackets are used   [option]
%%   curly  -  curly braces are used      {option}
%%   angle  -  angle brackets are used    <option>
%%   semicolon  -  multiple citations separated by semi-colon
%%   colon  - same as semicolon, an earlier confusion
%%   comma  -  separated by comma
%%   numbers-  selects numerical citations
%%   super  -  numerical citations as superscripts
%%   sort   -  sorts multiple citations according to order in ref. list
%%   sort&compress   -  like sort, but also compresses numerical citations
%%   compress - compresses without sorting
%%
%% \biboptions{comma,round}

% \biboptions{}

\providecommand{\OO}[1]{\operatorname{O}\bigl(#1\bigr)}

\graphicspath{
             {./Figures/}
             }

\long\def\symbolfootnote[#1]#2{\begingroup%
\def\thefootnote{\fnsymbol{footnote}}\footnote[#1]{#2}\endgroup}



\journal{NeuroImage}

\begin{document}


\begin{frontmatter}

\title{Multivariate Neuroanalysis with ANTsR:  Application to Supervised Brain Segmentation with Concatenated Random Forests}

\author[label1]{Nicholas J.~Tustison
  \fnref{label0}}
  \fntext[label0]{\scriptsize Corresponding author:  PO Box 801339, Charlottesville, VA 22908; T:  434-924-7730; email address:  ntustison@virginia.edu.
  }
\author[label2]{K.~L.~Shrinidhi}
\author[label2]{Jeffrey T.~Duda}
\author[label2]{Philip A.~Cook}
\author[label1]{Christopher Durst}
\author[label1]{Max Wintermark}
\author[label1]{James C.~Gee}
\author[label1]{Murray C.~Grossman}
\author[label2]{Brian B.~Avants}
\address[label1]{Department of Radiology and Medical Imaging, University of Virginia, Charlottesville, VA}
\address[label2]{Penn Image Computing and Science Laboratory, University of Pennsylvania,
                Philadelphia, PA}

%\maketitle

\linenumbers

\begin{abstract} 
Improvements in image acquisition and increasingly sophisticated statistical techniques 
for neuroanalysis have spurred the development of advanced computational frameworks for studying the
brain---many of which
have been made publicly available.  One such popular toolkit is the open source Advanced
Normalization Tools (ANTs) which contains a suite of well-vetted processing tools for
core data transformation tasks such as image registration, image segmentation, 
inhomogeneity field correction and template building.  However, despite the numerous
solutions afforded by such tools, neuroscience (and data analysis in general) requires
a statistical platform for making inferences with respect to given hypotheses once the 
requisite data transformations have been performed.  In this paper, we describe the
coupling of ANTs with the widely-used R language---an open source environment for 
statistical processing and data visualization---which we denote as ANTsR.  One of the
many benefits from such an integration is the accessibility to advanced statistical 
and machine learning techniques.  To showcase the flexibility and power of ANTsR, we 
apply the combination of one such technique, Random Forests, and ANTs processing 
tools to the difficult problem of brain tumor segmentation.  This includes evaluation on 
the public data set from the MICCAI 2012 BRATS challenge consisting of both real and simulated
data.  To facilitate reproducibility, all scripts and data used in this paper are 
publicly available for download.  
\end{abstract}

\begin{keyword}
advanced normalization tools \sep BRATS \sep brain tumor segmentation \sep R project \sep random forests
%% keywords here, in the form: keyword \sep keyword
\end{keyword}

\end{frontmatter}
%
%
\newpage

%% MSC codes here, in the form: \MSC code \sep code
%% or \MSC[2008] code \sep code (2000 is the default)

%%
%% Start line numbering here if you want
%%
% \linenumbers

%% The Appendices part is started with the command \appendix;
%% appendix sections are then done as normal sections
%% \appendix

%% \section{}
%% \label{}

%% References
%%
%% Following citation commands can be used in the body text:
%% Usage of \cite is as follows:
%%   \citep{key}          ==>>  [#]
%%   \cite[chap. 2]{key} ==>>  [#, chap. 2]
%%   \citet{key}         ==>>  Author [#]

%% main text

%\input{intro}
%
%\input{methods}

\section{Introduction}

ANTs (Advanced Normalization Tools) originated with the open source availing
of state-of-the-art registration algorithms for neuroimage analysis
\cite{avants2008a} built upon the mature and well-vetted Insight Toolkit
of the National Institutes of Health.  Since then, the toolkit has grown to include 
several algorithmic solutions necessary
for robust medical image analysis including bias correction \cite{tustison2010}, 
$n$-tissue multivariate segmentation \cite{avants2011}, template construction \cite{avants2010}, 
and cortical thickness estimation \cite{das2009} (many of which have been
introduced into ITK partially in an attempted leveraging of Linus's Law).%
\footnote{
``Given enough eyeballs, all bugs are shallow.'' --Linus Torvalds
}   
However, in the evolution of the toolkit, it became clear (as neuroimaging
research certainly falls under the popular rubric of ``big data analysis'')
that robust statistical machinery was lacking for proper inferences regarding
the data produced by the various ANTs tools.
ANTsR was developed
specifically to provide an interface between a 
powerful neuroimaging toolkit for producing reliable imaging data 
transformations and the R project%
\footnote{
http://www.r-project.org
}
for statistical computing and visualization thus providing a complete
set of tools for multivariate image analysis. 

In addition to describing ANTsR basics and how it can be generally
used in multivariate neuroimaging studies, we showcase its use in
a particularly salient application for performing supervised brain
segmentation using random forests.  Although random forests have
been proposed previously in the literature for supervised brain 
segmentation (e.g. \cite{geremia2011,zikic2012}), we demonstrate that ANTsR
significantly facilitates the construction of a fully functional, 
parallelizable workflow for such a task and that performance 
exceeds that of the top competitors in the recent Multimodal Brain
Tumor Segmentation Challenge as part of the MICCAI 2012 conference.%
\footnote{
http://www2.imm.dtu.dk/projects/BRATS2012/  
}

\section{Materials and Methods}

\subsection{ANTsR:  An ANTs/R Interface}

\subsubsection{Installation}

The ANTsR package is publicly available on the github project hosting service.%
\footnote{
https://github.com/stnava/ANTsR
}
Prior to installation of ANTsR, several external R packages
need to be installed including: \verb#Rcpp#, \verb#signal#, \verb#timeSeries#, 
\verb#mFilter#, \verb#doParallel#, \verb#robust#, \verb#magic#, \verb#knitr#, \verb#pixmap#, 
\verb#rgl#, \verb#misc3d# which is facilitated by the 
\verb#install.packages()# mechanism.  Additionally, in order
to perform the supervised brain segmentation as described 
in later sections, one would need to also install 
\verb#randomForest#, \verb#snowfall#, \verb#rlecuyer#,
and \verb#ggplot2#. 

CMake%
\footnote{
http://www.cmake.org/
}
is an open source tool for the management and building of 
large-scale software projects.  It is used
to coordinate the downloading of external packages,
such as the Insight Toolkit (ITK)%
\footnote{
http://www.itk.org/
}
and ANTs.  Detailed instructions for download and
installation can be found on the ANTsR github website.

\subsection{Supervised Brain Segmentation}

Given a set of training data consisting of 
labeled (csf, gray matter, white matter, edema, and tumor),
multimodal brain image data, 
supervised brain segmentation entails the generation of a 
statistical model from such training data which can
then be extended to testing data, i.e. unlabeled 
brain data.  In subsequent sections, we detail the generic
{\it random forest} modeling framework which takes as input
a set of {\it feature images} (also described in a later section)
and labels for each training subject 
and outputs a statistical model.  This model, in turn, can then
be used to provide a probabilistic estimate of the labels in an
unlabeled subject. 

One of the core extensions that we provide in this work is
the use of concatenated random forests for improved probabilistic estimation
of the labels.
As we demonstrate in the Results section, the set of feature
images employed work sufficiently well for good performance
on the training data (which exceeds that of what has been
currently published in the literature).  However, we discovered
that further improvements could be gained by using the probabilistic 
label estimates as input to enhance preprocessing before a 
second round of feature image generation including 
modality-specific, prior-based $n$-tissue segmentation and 
random forest model creation. 

\subsubsection{Random Forests}

Several machine learning concepts were integrated to create 
the random forests framework first articulated in its entirety by Breiman
et al. \cite{breiman2001} for performing classification/regression.  
Although decision trees had been previously explored in the literature, 
it was the success of ``boosting''-style machine learning 
techniques, such as AdaBoost \cite{schapire1990,freund1997}, which influenced 
the aggregation of such decision trees into ``forests'' 
with randomized node optimization for improved
classification/regression performance \cite{ho1995,amit1997}.
The final element of bootstrap aggregating or ``bagging'' (i.e.
random sampling of the training data) was
introduced by Breiman \cite{breiman1996} to achieve improved
accuracy.  

Early adoption \cite{viola2005} and success in the
computer vision community
has led to a recent surge within the medical image analysis
community of using random forests for handling complex 
classification/regression tasks including
normal brain segmentation \cite{yi2009},
MS lesion segmentation \cite{geremia2011}, 
multimodal brain tumor segmentation
\cite{zikic2012,geremia2012}, brain extraction \cite{iglesias2010}, 
anatomy detection in computed tomography \cite{criminisi2013}, and
segmentation of echocardiographic images \cite{verhoek2011}.
A thorough introduction for those interested in delving deeper 
into the more theoretical aspects of random forests can be found
in \cite{criminisi2011}.

One of the principal advantages of R is the extensive community of
developers  who have contributed on the order of thousands of packages 
extending R's capabilities beyond its core functionality.
Most relevant for the work described in this paper
is the \verb#randomForest# package developed from Breiman's original
Fortran code by Liaw and Wiener (described briefly in \cite{liaw2002}).


\subsubsection{Multi-Modal Feature Image Preprocessing}

Although several studies have pointed out the importance of
intensity normalization and bias correction, our experience 
with the training data illustrated a degradation in performance
when one or both steps (using \cite{nyul2000} and N4 \cite{tustison2010},
respectively) were performed due to the presence of the tumor/edema complex. 
 
As a corrective, for the first stage we simply windowed the image intensity
for all images to be between the quantiles $[0.01,0.99]$ and
subsequently rescaled to $[0,1]$.  From these ``corrected'' images,
the first set of feature images were derived.  For the training cohort, these
data were used to create the random forest regression model for the first
stage.  During the second stage, the probabilistic estimates
of the white matter and gray matter labels were used to generate a
``pure tissue weight mask'' to estimate the bias field 
using N4 (although the resulting bias field estimation was used
to correct the image within the entire cerebral mask).  Formally, this 
involved generation of a probabilistic map defined as:
\begin{align}
  P_{pure\,\,tissue}(\mathbf{x}) = \sum_{i=1}^N P_i(\mathbf{x}) \prod_{j=1, j \neq i}^N \left( 1 - P_j(\mathbf{x}) \right)
\end{align}
where $N$ is the set of user-selected tissue labels (in our
case $N=2$ consisting of the gray and white matter probability
maps).

Both rescaling and weighted bias correction were applied to produce
the ``corrected images'' for the second stage resulting in
modified features images for the second stage.  Note that we
perform a similar iterative scenario for normal brain 
segmentation \cite{avants2011} (encapsulated in the ANTs script 
\verb#antsAtroposN4.sh#).

\subsubsection{Multi-Modal Feature Image Generation}

Key to any supervised regression or classification protocol are the 
selected features for training and subsequent testing.  Based on previous
work and our own experience, we selected the following feature images
to showcase the supervised segmentation strategy developed in this work.

\begin{figure*}
  \centering
  \includegraphics[width=180mm]{Figures/featuresImages.pdf}
  \caption{Feature images from the BRATS\_HG0004 data set.}
\end{figure*}

\begin{itemize}
  \item Per modality (FLAIR, T1, T1C, T2)
    \begin{itemize}
      \item First-order neighborhood statistical images:
            mean, variance, skewness, and entropy. 
            Neighborhood radius = 3.
    \item GMM-based posteriors: CSF, gray matter, white matter, edema, and tumor
    \item GMM connected component geometry features:  volume, volume to 
          surface area ratio, eccentricity, elongation
    \item Template-based:  symmetric template difference and contralateral difference.
          Gaussian smoothing ($\sigma = 4$mm).
    \end{itemize}
  \item Not modality specific
    \begin{itemize}
    \item Normalized Euclidean distance
    \item Log Jacobian  
    \item T1C,T1 difference image
    \end{itemize}
\end{itemize}

For each modality, we create four first-order statistical feature images,
five Gaussian mixture model (GMM)-based posterior probability feature images,
four geometry features generated from the GMM posterior probability images
based on connected components, and two difference images using symmetric template
construction for a total of 4 modalities $\times$ (4 + 5 + 4 + 2) feature images per modality $=$ 60 total
feature images.  We employ two additional images consisting of the 
Euclidean distance image \cite{maurer2003} created from the skull-stripped 
binary mask rescaled to the range $[0,1]$ and the log
Jacobian image derived from the spatial normalization of the symmetric multivariate template and individual subject images.  Given the intensity corrected images
the corresponding multivariate template images, and a brain mask for each subject
creation of all feature images is performed using the script \verb#createFeatureImages.sh#.

Prior  cluster centers for specific tissue types learned from training data \cite{reynolds2009} are used in the GMM to create multiple feature images.  
Given $M$ tissue types (e.g. CSF, gray matter,
white matter, edema, and tumor), a GMM formulates the 
probability distribution at each voxel, $\mathbf{x}$, as the
sum of Gaussian components, $\mathcal{N}(\mathbf{x}|\mu,\sigma)$, i.e.
\begin{align}
p\left(\mathbf{x}|\mu_m,\sigma_m,\lambda_m\right) = \sum_{i=1}^M \lambda_m \mathcal{N}(\mathbf{x}|\mu_m,\sigma_m)
\end{align}
where $\sum_{m=1}^M \lambda_m = 1$.  One popular method for 
determining the parameters of the GMM is maximum likelihood 
estimation which can performed using the Atropos segmentation 
tool \cite{avants2011}.  In contrast to previous generative
modeling approaches for multi-modal tumor segmentation 
(e.g. \cite{prastawa2003,zikic2012}), we do not use multivariate 
Gaussians to specify tissue probabilities but rather incorporate each
univariate probability map into the feature vector of the training
data.  As pointed out in \cite{menze2010}, multivariate modeling
might obscure the distinct biological information provided by each 
modality.  Instead, we let the random forest construction 
process determine the optimal combination of such multivariate
information.
Additionally, maximum posterior labeling from the GMM processing
is used to determine the connected components for each label.  
Geometric features (assigned voxel-wise) include the physical volumes 
of each connected component including the volume to surface area ratio, 
the elongation, and eccentricity. 

In order to better characterize deviations from normal
multi-modal brain shape and appearance, several features were derived 
using population-specific multivariate template 
construction. A recent neuroimaging reproducibility study
by Landman et al. resulted in an open data cohort of 21
normal individuals, each imaged twice, comprising several
modalities including arterial spin labeling, 
fluid attenuated inversion recovery (FLAIR),
diffusion tensor imaging, functional imaging, T1, and T2 
\cite{landman2011}.

Given $K$ image modality types for $N$ subjects,  
${\mathbf I} = \{I_1,I_2,\ldots, I_K\}$, multivariate 
template construction iterates between optimizing the set 
of diffeomorphic transforms between the subjects and the 
template, 
$\left\{\left(\phi_1,\phi_1^{-1}\right),\ldots,\left(\phi_N,\phi_N^{-1}\right)\right\}$ 
and constructing the 
optimal multivariate template appearance 
$\mathbf{J}=\{J_1,J_2,\ldots, J_K\}$ to minimize the
following cost function:
\begin{align}
  \sum_{n=1}^N 
        \Bigg[ D &\left( \psi(\mathbf{x}),\phi_1^n(\mathbf{x},1)\right) \\ \nonumber 
        +& \sum_{k=1}^K \lambda_k \Pi_k \left(I_k^n\left(\phi_n(\mathbf{x},0.5)\right),J_k\left(\phi^{-1}_n(\mathbf{x},0.5)\right)\right)\Bigg]
\end{align}
where $D$ is the diffeomorphic shape distance,
\begin{align}
D\left( \phi( \mathbf{x},0),\phi( \mathbf{x},1)\right) = \int_0^1 \| \nu(\mathbf{x},t)\|_L dt
\end{align}
dependent on the choice of linear operator, $L$, and $\nu$
is the velocity field
\begin{align}
\nu\left( \phi(\mathbf{x},t) \right) = \frac{d\phi(\mathbf{x},t)}{dt},\,\,\, \phi(\mathbf{x},0) = \mathbf{x}.
\end{align}
Each pairwise registration employing the similarity metric $\Pi_k$ can 
be assigned a relative weighting, $\lambda_k$, to weight a particular
modality's influence in the construction process.  Further theoretical
details can be found in \cite{avants2008,avants2010}.
In terms of implementation, this algorithm is 
encapsulated in the script \verb#antsMultivariateTemplateConstruction.sh#,
available in the ANTs repository, which permits parallel processing on
an individual workstation or on a large computational cluster.

\begin{figure}
  \centering
  \begin{tabular}{cc}
    \includegraphics[width=40mm]{Figures/S_templateFA_140.png} &
    \includegraphics[width=40mm]{Figures/S_templateFLAIR_140.png} \\
    (a) & (b) \\
    \includegraphics[width=40mm]{Figures/S_templateT1_140.png} &
    \includegraphics[width=40mm]{Figures/S_templateT2_140.png} \\
    (c) & (d) 
  \end{tabular}
  \caption{Multivariate symmetric template created from the Kirby 
           21 data described in \cite{landman2011}.  Shown are the
           (a) fractional anisotropy (FA), (b) FLAIR, (c) MPRAGE, 
           and (d) T2 template components.
          }
  \label{fig:symmetrictemplates}
\end{figure}








\subsubsection{\underline{Bra}in \underline{T}umor \underline{S}egmentation Challenge Data}

The Brain tumor segmentation
Associated with the 2012 International Conference on Medical Image Computing and Computer Assisted
Intervention (MICCAI),%
\footnote{
http://www.miccai2012.org
}
the 


\subsubsection{MS lesion segmentation challenge Challenge Data}

\section{Results}

\begin{table*}
\caption{Dice scores from the MICCAI 2012 BRATs Study}
\begin{center}
\begin{tabular*}{0.975\textwidth}{@{\extracolsep{\fill} } c c c c c c c c c}
\toprule
{} & \multicolumn{2}{c}{High-grade (real)} & \multicolumn{2}{c}{Low-grade (real)} & \multicolumn{2}{c}{High-grade (simulated)} & \multicolumn{2}{c}{Low-grade (simulated)}\\
{\bf Method} & Edema & Tumor & Edema & Tumor & Edema & Tumor & Edema & Tumor\\
\midrule
\cite{zikic2012} & {$0.70 \pm 0.09$} & {$0.71 \pm 0.24$} & {$0.44 \pm 0.18$} & {$0.62 \pm 0.27$} & {$0.65 \pm 0.27$} & {$0.90 \pm 0.05$} & {$0.55 \pm 0.23$} & {$0.71 \pm 0.20$} \\
\cite{bauer2012} & {$0.61 \pm 0.15$} & {$0.62 \pm 0.27$} & {$0.35 \pm 0.18$} & {$0.49 \pm 0.26$} & {$0.68 \pm 0.26$} & {$0.90 \pm 0.06$} & {$0.57 \pm 0.24$} & {$0.74 \pm 0.10$} \\
ANTsR & {$0.65 \pm 0.15$} & {$0.66 \pm 0.28$} & {$0.49 \pm 0.16$} & {$0.65 \pm 0.21$} & {$0.68 \pm 0.25$} & {$0.91 \pm 0.08$} & {$0.61 \pm 0.25$} & {$0.84 \pm 0.09$} \\
w/ Atropos & {$0.68 \pm 0.15$} & {$0.67 \pm 0.30$} & {$0.50 \pm 0.15$} & {$0.67 \pm 0.23$} & {$0.74 \pm 0.26$} & {$0.92 \pm 0.09$} & {$0.65 \pm 0.26$} & {$0.84\pm 0.08$} \\
\bottomrule
\end{tabular*}
\end{center}
\end{table*}

\section{Discussion and Conclusions} 

%% References with bibTeX database:

\section*{Acknowledgments}

\section*{References}

\bibliographystyle{elsarticle-harv}
\bibliography{references}


%% Authors are advised to submit their bibtex database files. They are
%% requested to list a bibtex style file in the manuscript if they do
%% not want to use model1-num-names.bst.

%% References without bibTeX database:

% \begin{thebibliography}{00}

%% \bibitem must have the following form:
%%   \bibitem{key}...
%%

% \bibitem{}

% \end{thebibliography}


\end{document}

%%
%% End of file `elsarticle-template-1-num.tex'.
